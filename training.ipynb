{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model Training",
   "id": "406a275748fc4ae1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Prepare dataframe ",
   "id": "5185c4c214683a8a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T21:46:55.449983Z",
     "start_time": "2024-09-13T21:46:42.767464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from nltk import sent_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from utils.text_preprocess import LemmaTokenizer\n",
    "\n",
    "df = pd.read_csv('data/amazon_reviews.txt', sep='\\t')\n",
    "df['VERIFIED_PURCHASE'] = df['VERIFIED_PURCHASE'].map({'Y': 1, 'N': 0})\n",
    "\n",
    "word2vec_model_file = 'models/word2vec_200.model'\n",
    "model = Word2Vec.load(word2vec_model_file)\n",
    "\n",
    "def average_word_embeddings(sentence, model):\n",
    "    words = LemmaTokenizer()(sentence)\n",
    "    word_vectors = [model.wv[word] for word in words if word in model.wv]\n",
    "    \n",
    "    if len(word_vectors) == 0:\n",
    "        return np.zeros(model.vector_size)\n",
    "    \n",
    "    return np.mean(word_vectors, axis=0)\n",
    "\n",
    "# Define a function to process each review\n",
    "def process_review(review_text, model):\n",
    "    sentences = sent_tokenize(review_text)\n",
    "    sentence_embeddings = [average_word_embeddings(sentence, model) for sentence in sentences]\n",
    "    return sentence_embeddings\n",
    "\n",
    "df['Sentence_Embeddings'] = df['REVIEW_TEXT'].apply(lambda x: process_review(x, model))\n"
   ],
   "id": "9d484cd9e4e6b1c6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\PycharmProjects\\amazon_fake_reviews_detection\\utils\\text_preprocess.py:30: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  text = BeautifulSoup(text, \"html.parser\").get_text()\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create pipelines",
   "id": "51b2984b39e567b6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T21:46:55.459941Z",
     "start_time": "2024-09-13T21:46:55.453498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils.transformers import *\n",
    "    \n",
    "classifiers = [\n",
    "    RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "    CalibratedClassifierCV(LinearSVC(random_state=42, dual=False)),\n",
    "    MultinomialNB(),\n",
    "]\n",
    "vectorizers = [\n",
    "    TfidfVectorizer(tokenizer=LemmaTokenizer(), token_pattern=None),\n",
    "    CountVectorizer(tokenizer=LemmaTokenizer(), token_pattern=None),\n",
    "]\n",
    "\n",
    "pipes = []\n",
    "pipes_names = []\n",
    "for clf in classifiers:\n",
    "    for vectorizer in vectorizers:\n",
    "        for useEmbeddings in [True, False]:\n",
    "            for useVP in [True, False]:\n",
    "                transformers = [\n",
    "                    ('vectorizer', vectorizer, 'REVIEW_TEXT')\n",
    "                ]\n",
    "                if useEmbeddings:\n",
    "                    transformers.append(('embeddings', SentenceEmbeddingTransformer(), 'Sentence_Embeddings'))\n",
    "                if useVP:\n",
    "                    transformers.append(('encoder', OneHotEncoder(), ['VERIFIED_PURCHASE']))\n",
    "                \n",
    "                if isinstance(clf, MultinomialNB):\n",
    "                    # Add DenseTransformer after ColumnTransformer to convert the full sparse matrix to dense\n",
    "                    pipes.append(Pipeline([\n",
    "                        ('preprocessor', ColumnTransformer(transformers, n_jobs=-1)),\n",
    "                        ('to_dense', DenseTransformer()),  # Apply DenseTransformer here\n",
    "                        ('clf', clf)\n",
    "                    ]))\n",
    "                else:\n",
    "                    # No need for DenseTransformer for other classifiers\n",
    "                    pipes.append(Pipeline([\n",
    "                        ('preprocessor', ColumnTransformer(transformers, n_jobs=-1)),\n",
    "                        ('clf', clf)\n",
    "                    ]))\n",
    "                    \n",
    "                pipes_names.append(f'{clf.__class__.__name__}_'\n",
    "                                   f'{vectorizer.__class__.__name__}'\n",
    "                                   f'{\"_WE\" if useEmbeddings else \"\"}'\n",
    "                                   f'{\"_VP\" if useVP else \"\"}')"
   ],
   "id": "b2c4919bcc0b9509",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Nested cross-validation",
   "id": "9d80d859f9116171"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-09-13T21:46:55.519486Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from nltk import sent_tokenize\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import cross_val_score, HalvingGridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from utils.text_preprocess import LemmaTokenizer\n",
    "\n",
    "\n",
    "param_grids = {\n",
    "    'RandomForestClassifier': {\n",
    "        'clf__n_estimators': [800, 1000, 1200],\n",
    "        'clf__criterion': ['entropy', 'log_loss'],\n",
    "        'clf__max_depth': [None, 20, 40, 60],\n",
    "        'clf__bootstrap': [False, True],\n",
    "    },\n",
    "    'CalibratedClassifierCV': {\n",
    "        'clf__estimator__C': [0.5, 1, 1.5],\n",
    "        'clf__estimator__max_iter': [2000, 4000],\n",
    "        'clf__estimator__loss': ['hinge', 'squared_hinge'],\n",
    "    },\n",
    "    'MultinomialNB': {\n",
    "        'clf__alpha': [0.0001, 0.001, 0.1, 0.5, 1.0],\n",
    "    }\n",
    "}\n",
    "\n",
    "inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "outer_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "results = {}\n",
    "best_accuracy = 0\n",
    "best_model = None\n",
    "\n",
    "for pipe, pipe_name in zip(pipes, pipes_names):\n",
    "    print(pipe_name)\n",
    "    clf_name = pipe.steps[-1][1].__class__.__name__\n",
    "    grid = param_grids[clf_name]\n",
    "    clf = HalvingGridSearchCV(pipe, grid, cv=inner_cv, factor=2, random_state=42, n_jobs=-1)\n",
    "    results[pipe_name] = [[], [], [], []]\n",
    "    \n",
    "    # Loop instead of cross_val_score to have more control over printing\n",
    "    for fold, (train_idx, test_idx) in enumerate(outer_cv.split(df, df['LABEL'])):\n",
    "        print(f\"Fold {fold}:\")\n",
    "        \n",
    "        # Split the data\n",
    "        X_train, X_test = df.iloc[train_idx], df.iloc[test_idx]\n",
    "        y_train, y_test = df['LABEL'].iloc[train_idx], df['LABEL'].iloc[test_idx]\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        results[pipe_name][0].append(accuracy_score(y_test, y_pred))\n",
    "        results[pipe_name][1].append(f1_score(y_test, y_pred, pos_label='__label1__'))\n",
    "        results[pipe_name][2].append(roc_auc_score(y_test, clf.predict_proba(X_test)[:,1]))\n",
    "        results[pipe_name][3].append(clf.best_params_)\n",
    "        \n",
    "        # Update best model \n",
    "        if results[pipe_name][0][-1] > best_accuracy:\n",
    "            best_accuracy = results[pipe_name][0][-1]\n",
    "            best_model = clf.best_estimator_\n",
    "\n",
    "        print(f\"Best params: {clf.best_params_}\\n\"\n",
    "              f\"Test accuracy: { results[pipe_name][0][-1]}\\n\"\n",
    "              f\"Test F1: { results[pipe_name][1][-1]}\\n\"\n",
    "              f\"Test AUC: { results[pipe_name][2][-1]}\\n\")\n",
    "    \n",
    "    print(f'Mean Accuracy: {np.mean(results[pipe_name][0])}\\n'\n",
    "          f'Mean F1: {np.mean(results[pipe_name][1])}\\n'\n",
    "          f'Mean AUC: {np.mean(results[pipe_name][2])}\\n')\n",
    "\n",
    "# save results to csv file\n",
    "results_str = {key: [str(value) for value in values] for key, values in results.items()}\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for key, value in results_str.items():\n",
    "    temp_df = pd.DataFrame([value], columns=['accuracy', 'f1_score', 'AUC', 'hyperparameters'])\n",
    "    temp_df.insert(0, 'model', key)\n",
    "    df = pd.concat([df, temp_df], ignore_index=True)\n",
    "df.to_csv('results.csv', index=False)\n",
    "\n",
    "# save best model\n",
    "joblib.dump(best_model, 'best_model.pkl')"
   ],
   "id": "4e135cda31eea7a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier_TfidfVectorizer_WE_VP\n",
      "Fold 0:\n",
      "Best params: {'clf__bootstrap': False, 'clf__criterion': 'entropy', 'clf__max_depth': 60, 'clf__n_estimators': 1000}\n",
      "Test accuracy: 0.7980952380952381\n",
      "Test F1: 0.7965451055662188\n",
      "Test AUC: 0.8655809523809525\n",
      "\n",
      "Fold 1:\n",
      "Best params: {'clf__bootstrap': True, 'clf__criterion': 'log_loss', 'clf__max_depth': 40, 'clf__n_estimators': 1200}\n",
      "Test accuracy: 0.7976190476190477\n",
      "Test F1: 0.7927840078010727\n",
      "Test AUC: 0.8639555555555556\n",
      "\n",
      "Fold 2:\n",
      "Best params: {'clf__bootstrap': False, 'clf__criterion': 'entropy', 'clf__max_depth': 40, 'clf__n_estimators': 1000}\n",
      "Test accuracy: 0.8076190476190476\n",
      "Test F1: 0.804642166344294\n",
      "Test AUC: 0.8682113378684807\n",
      "\n",
      "Fold 3:\n",
      "Best params: {'clf__bootstrap': True, 'clf__criterion': 'log_loss', 'clf__max_depth': 60, 'clf__n_estimators': 1200}\n",
      "Test accuracy: 0.7880952380952381\n",
      "Test F1: 0.7838756677999028\n",
      "Test AUC: 0.8615224489795918\n",
      "\n",
      "Fold 4:\n",
      "Best params: {'clf__bootstrap': False, 'clf__criterion': 'entropy', 'clf__max_depth': 60, 'clf__n_estimators': 1000}\n",
      "Test accuracy: 0.8114285714285714\n",
      "Test F1: 0.8070175438596491\n",
      "Test AUC: 0.8719986394557823\n",
      "\n",
      "Fold 5:\n",
      "Best params: {'clf__bootstrap': False, 'clf__criterion': 'entropy', 'clf__max_depth': None, 'clf__n_estimators': 1200}\n",
      "Test accuracy: 0.8171428571428572\n",
      "Test F1: 0.8113948919449901\n",
      "Test AUC: 0.8828394557823128\n",
      "\n",
      "Fold 6:\n",
      "Best params: {'clf__bootstrap': True, 'clf__criterion': 'log_loss', 'clf__max_depth': None, 'clf__n_estimators': 1200}\n",
      "Test accuracy: 0.8019047619047619\n",
      "Test F1: 0.7972709551656919\n",
      "Test AUC: 0.8693487528344671\n",
      "\n",
      "Fold 7:\n",
      "Best params: {'clf__bootstrap': False, 'clf__criterion': 'entropy', 'clf__max_depth': None, 'clf__n_estimators': 1000}\n",
      "Test accuracy: 0.8195238095238095\n",
      "Test F1: 0.8155717761557179\n",
      "Test AUC: 0.8862253968253968\n",
      "\n",
      "Fold 8:\n",
      "Best params: {'clf__bootstrap': True, 'clf__criterion': 'log_loss', 'clf__max_depth': 60, 'clf__n_estimators': 1000}\n",
      "Test accuracy: 0.7876190476190477\n",
      "Test F1: 0.7837051406401552\n",
      "Test AUC: 0.8509755102040816\n",
      "\n",
      "Fold 9:\n",
      "Best params: {'clf__bootstrap': False, 'clf__criterion': 'entropy', 'clf__max_depth': None, 'clf__n_estimators': 1000}\n",
      "Test accuracy: 0.8033333333333333\n",
      "Test F1: 0.8021082894106373\n",
      "Test AUC: 0.8694086167800454\n",
      "\n",
      "Mean Accuracy: 0.8032380952380953\n",
      "Mean F1: 0.799491554468833\n",
      "Mean AUC: 0.8690066666666667\n",
      "\n",
      "RandomForestClassifier_TfidfVectorizer_WE_\n",
      "Fold 0:\n",
      "Best params: {'clf__bootstrap': False, 'clf__criterion': 'log_loss', 'clf__max_depth': 40, 'clf__n_estimators': 1000}\n",
      "Test accuracy: 0.6442857142857142\n",
      "Test F1: 0.6410379625180203\n",
      "Test AUC: 0.6998757369614512\n",
      "\n",
      "Fold 1:\n",
      "Best params: {'clf__bootstrap': False, 'clf__criterion': 'entropy', 'clf__max_depth': 40, 'clf__n_estimators': 1000}\n",
      "Test accuracy: 0.6580952380952381\n",
      "Test F1: 0.6641721234798877\n",
      "Test AUC: 0.7169777777777777\n",
      "\n",
      "Fold 2:\n",
      "Best params: {'clf__bootstrap': False, 'clf__criterion': 'entropy', 'clf__max_depth': 40, 'clf__n_estimators': 1200}\n",
      "Test accuracy: 0.6271428571428571\n",
      "Test F1: 0.6332552693208431\n",
      "Test AUC: 0.696863492063492\n",
      "\n",
      "Fold 3:\n",
      "Best params: {'clf__bootstrap': False, 'clf__criterion': 'entropy', 'clf__max_depth': None, 'clf__n_estimators': 1000}\n",
      "Test accuracy: 0.6390476190476191\n",
      "Test F1: 0.651012891344383\n",
      "Test AUC: 0.7057818594104307\n",
      "\n",
      "Fold 4:\n",
      "Best params: {'clf__bootstrap': False, 'clf__criterion': 'log_loss', 'clf__max_depth': 60, 'clf__n_estimators': 800}\n",
      "Test accuracy: 0.6438095238095238\n",
      "Test F1: 0.6471698113207547\n",
      "Test AUC: 0.7036684807256236\n",
      "\n",
      "Fold 5:\n",
      "Best params: {'clf__bootstrap': False, 'clf__criterion': 'log_loss', 'clf__max_depth': 40, 'clf__n_estimators': 1200}\n",
      "Test accuracy: 0.6757142857142857\n",
      "Test F1: 0.6868965517241379\n",
      "Test AUC: 0.737208163265306\n",
      "\n",
      "Fold 6:\n",
      "Best params: {'clf__bootstrap': False, 'clf__criterion': 'entropy', 'clf__max_depth': 40, 'clf__n_estimators': 1000}\n",
      "Test accuracy: 0.6414285714285715\n",
      "Test F1: 0.6496044671940437\n",
      "Test AUC: 0.694722902494331\n",
      "\n",
      "Fold 7:\n",
      "Best params: {'clf__bootstrap': False, 'clf__criterion': 'entropy', 'clf__max_depth': None, 'clf__n_estimators': 1200}\n",
      "Test accuracy: 0.6604761904761904\n",
      "Test F1: 0.6638378123526638\n",
      "Test AUC: 0.7224349206349205\n",
      "\n",
      "Fold 8:\n",
      "Best params: {'clf__bootstrap': True, 'clf__criterion': 'entropy', 'clf__max_depth': None, 'clf__n_estimators': 800}\n",
      "Test accuracy: 0.6361904761904762\n",
      "Test F1: 0.6446511627906977\n",
      "Test AUC: 0.6811854875283446\n",
      "\n",
      "Fold 9:\n",
      "Best params: {'clf__bootstrap': False, 'clf__criterion': 'entropy', 'clf__max_depth': None, 'clf__n_estimators': 1200}\n",
      "Test accuracy: 0.6309523809523809\n",
      "Test F1: 0.6413697362332254\n",
      "Test AUC: 0.6912743764172335\n",
      "\n",
      "Mean Accuracy: 0.6457142857142857\n",
      "Mean F1: 0.6523007788278657\n",
      "Mean AUC: 0.7049993197278911\n",
      "\n",
      "RandomForestClassifier_TfidfVectorizer__VP\n",
      "Fold 0:\n",
      "Best params: {'clf__bootstrap': False, 'clf__criterion': 'entropy', 'clf__max_depth': 60, 'clf__n_estimators': 1200}\n",
      "Test accuracy: 0.8104761904761905\n",
      "Test F1: 0.8008008008008008\n",
      "Test AUC: 0.8738312925170069\n",
      "\n",
      "Fold 1:\n",
      "Best params: {'clf__bootstrap': True, 'clf__criterion': 'log_loss', 'clf__max_depth': 20, 'clf__n_estimators': 1200}\n",
      "Test accuracy: 0.8061904761904762\n",
      "Test F1: 0.7918158567774936\n",
      "Test AUC: 0.8558920634920636\n",
      "\n",
      "Fold 2:\n",
      "Best params: {'clf__bootstrap': False, 'clf__criterion': 'log_loss', 'clf__max_depth': 40, 'clf__n_estimators': 1200}\n",
      "Test accuracy: 0.8095238095238095\n",
      "Test F1: 0.7987927565392354\n",
      "Test AUC: 0.8705224489795919\n",
      "\n",
      "Fold 3:\n",
      "Best params: {'clf__bootstrap': False, 'clf__criterion': 'entropy', 'clf__max_depth': 40, 'clf__n_estimators': 1200}\n",
      "Test accuracy: 0.8019047619047619\n",
      "Test F1: 0.7888324873096447\n",
      "Test AUC: 0.8686920634920635\n",
      "\n",
      "Fold 4:\n",
      "Best params: {'clf__bootstrap': True, 'clf__criterion': 'log_loss', 'clf__max_depth': 60, 'clf__n_estimators': 1200}\n",
      "Test accuracy: 0.8038095238095239\n",
      "Test F1: 0.7904374364191251\n",
      "Test AUC: 0.8747092970521542\n",
      "\n",
      "Fold 5:\n",
      "Best params: {'clf__bootstrap': True, 'clf__criterion': 'entropy', 'clf__max_depth': 20, 'clf__n_estimators': 1200}\n",
      "Test accuracy: 0.8104761904761905\n",
      "Test F1: 0.795897435897436\n",
      "Test AUC: 0.8792662131519273\n",
      "\n",
      "Fold 6:\n",
      "Best params: {'clf__bootstrap': True, 'clf__criterion': 'entropy', 'clf__max_depth': 20, 'clf__n_estimators': 1000}\n",
      "Test accuracy: 0.8042857142857143\n",
      "Test F1: 0.7895545314900154\n",
      "Test AUC: 0.8744226757369616\n",
      "\n",
      "Fold 7:\n",
      "Best params: {'clf__bootstrap': False, 'clf__criterion': 'log_loss', 'clf__max_depth': 40, 'clf__n_estimators': 1200}\n",
      "Test accuracy: 0.82\n",
      "Test F1: 0.8067484662576687\n",
      "Test AUC: 0.8868743764172337\n",
      "\n",
      "Fold 8:\n",
      "Best params: {'clf__bootstrap': True, 'clf__criterion': 'log_loss', 'clf__max_depth': 20, 'clf__n_estimators': 1000}\n",
      "Test accuracy: 0.7961904761904762\n",
      "Test F1: 0.7807377049180328\n",
      "Test AUC: 0.8521124716553288\n",
      "\n",
      "Fold 9:\n",
      "Best params: {'clf__bootstrap': True, 'clf__criterion': 'entropy', 'clf__max_depth': 20, 'clf__n_estimators': 1000}\n",
      "Test accuracy: 0.8066666666666666\n",
      "Test F1: 0.7955689828801611\n",
      "Test AUC: 0.8658585034013605\n",
      "\n",
      "Mean Accuracy: 0.806952380952381\n",
      "Mean F1: 0.7939186459289613\n",
      "Mean AUC: 0.8702181405895691\n",
      "\n",
      "RandomForestClassifier_TfidfVectorizer__\n",
      "Fold 0:\n",
      "Best params: {'clf__bootstrap': True, 'clf__criterion': 'log_loss', 'clf__max_depth': None, 'clf__n_estimators': 1200}\n",
      "Test accuracy: 0.6419047619047619\n",
      "Test F1: 0.6422454804947669\n",
      "Test AUC: 0.7010816326530612\n",
      "\n",
      "Fold 1:\n",
      "Best params: {'clf__bootstrap': True, 'clf__criterion': 'log_loss', 'clf__max_depth': 60, 'clf__n_estimators': 1200}\n",
      "Test accuracy: 0.6604761904761904\n",
      "Test F1: 0.6742804933759707\n",
      "Test AUC: 0.7100299319727891\n",
      "\n",
      "Fold 2:\n",
      "Best params: {'clf__bootstrap': True, 'clf__criterion': 'entropy', 'clf__max_depth': 60, 'clf__n_estimators': 1200}\n",
      "Test accuracy: 0.6319047619047619\n",
      "Test F1: 0.6442705936493328\n",
      "Test AUC: 0.6970539682539681\n",
      "\n",
      "Fold 3:\n",
      "Best params: {'clf__bootstrap': True, 'clf__criterion': 'entropy', 'clf__max_depth': None, 'clf__n_estimators': 800}\n",
      "Test accuracy: 0.6585714285714286\n",
      "Test F1: 0.6666666666666666\n",
      "Test AUC: 0.720682993197279\n",
      "\n",
      "Fold 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utente\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'clf__bootstrap': False, 'clf__criterion': 'log_loss', 'clf__max_depth': None, 'clf__n_estimators': 1200}\n",
      "Test accuracy: 0.6519047619047619\n",
      "Test F1: 0.6623556581986143\n",
      "Test AUC: 0.7151020408163266\n",
      "\n",
      "Fold 5:\n",
      "Best params: {'clf__bootstrap': True, 'clf__criterion': 'entropy', 'clf__max_depth': 40, 'clf__n_estimators': 800}\n",
      "Test accuracy: 0.6628571428571428\n",
      "Test F1: 0.6761207685269899\n",
      "Test AUC: 0.739482993197279\n",
      "\n",
      "Fold 6:\n",
      "Best params: {'clf__bootstrap': True, 'clf__criterion': 'log_loss', 'clf__max_depth': 40, 'clf__n_estimators': 1200}\n",
      "Test accuracy: 0.6461904761904762\n",
      "Test F1: 0.6666666666666667\n",
      "Test AUC: 0.7089269841269842\n",
      "\n",
      "Fold 7:\n",
      "Best params: {'clf__bootstrap': True, 'clf__criterion': 'log_loss', 'clf__max_depth': 60, 'clf__n_estimators': 1200}\n",
      "Test accuracy: 0.66\n",
      "Test F1: 0.6721763085399449\n",
      "Test AUC: 0.7242585034013606\n",
      "\n",
      "Fold 8:\n",
      "Best params: {'clf__bootstrap': True, 'clf__criterion': 'log_loss', 'clf__max_depth': 40, 'clf__n_estimators': 1000}\n",
      "Test accuracy: 0.6404761904761904\n",
      "Test F1: 0.6572855197458012\n",
      "Test AUC: 0.7010439909297053\n",
      "\n",
      "Fold 9:\n",
      "Best params: {'clf__bootstrap': True, 'clf__criterion': 'log_loss', 'clf__max_depth': 40, 'clf__n_estimators': 800}\n",
      "Test accuracy: 0.6223809523809524\n",
      "Test F1: 0.6364053186611647\n",
      "Test AUC: 0.6885106575963719\n",
      "\n",
      "Mean Accuracy: 0.6476666666666666\n",
      "Mean F1: 0.6598473474525919\n",
      "Mean AUC: 0.7106173696145125\n",
      "\n",
      "RandomForestClassifier_CountVectorizer_WE_VP\n",
      "Fold 0:\n",
      "Best params: {'clf__bootstrap': True, 'clf__criterion': 'log_loss', 'clf__max_depth': 40, 'clf__n_estimators': 1200}\n",
      "Test accuracy: 0.7928571428571428\n",
      "Test F1: 0.7907647907647907\n",
      "Test AUC: 0.8624390022675736\n",
      "\n",
      "Fold 1:\n",
      "Best params: {'clf__bootstrap': False, 'clf__criterion': 'log_loss', 'clf__max_depth': 20, 'clf__n_estimators': 1200}\n",
      "Test accuracy: 0.8042857142857143\n",
      "Test F1: 0.7986281234688879\n",
      "Test AUC: 0.865861224489796\n",
      "\n",
      "Fold 2:\n",
      "Best params: {'clf__bootstrap': False, 'clf__criterion': 'entropy', 'clf__max_depth': 60, 'clf__n_estimators': 1000}\n",
      "Test accuracy: 0.8066666666666666\n",
      "Test F1: 0.8038647342995169\n",
      "Test AUC: 0.866091156462585\n",
      "\n",
      "Fold 3:\n",
      "Best params: {'clf__bootstrap': True, 'clf__criterion': 'log_loss', 'clf__max_depth': None, 'clf__n_estimators': 1000}\n",
      "Test accuracy: 0.7919047619047619\n",
      "Test F1: 0.7879670063076176\n",
      "Test AUC: 0.8602734693877551\n",
      "\n",
      "Fold 4:\n",
      "Best params: {'clf__bootstrap': False, 'clf__criterion': 'entropy', 'clf__max_depth': 40, 'clf__n_estimators': 1200}\n",
      "Test accuracy: 0.809047619047619\n",
      "Test F1: 0.8046760837798345\n",
      "Test AUC: 0.8697378684807257\n",
      "\n",
      "Fold 5:\n",
      "Best params: {'clf__bootstrap': True, 'clf__criterion': 'entropy', 'clf__max_depth': 40, 'clf__n_estimators': 1200}\n",
      "Test accuracy: 0.8095238095238095\n",
      "Test F1: 0.8029556650246306\n",
      "Test AUC: 0.8777750566893424\n",
      "\n",
      "Fold 6:\n"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
